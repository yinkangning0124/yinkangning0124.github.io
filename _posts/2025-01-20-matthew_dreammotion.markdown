---
layout: post
title:  "MotionDreamer: One-to-More Motion Synthesis with Localized Generative Masked Transformer"
date:   2025-01-20 22:21:59 +00:00
image: /images/dreammotion25.gif
categories: research
author: "Yuxuan Mu"
authors: "<a href=https://vision-and-learning-lab-ualberta.github.io/author/yilin-wang/>Yilin Wang</a>, <a href=https://ericguo5513.github.io>Chuan Guo</a>, <strong>Yuxuan Mu</strong>, <a href=https://gohar-malik.github.io/>Muhammad Gohar Javed</a>, <a href=https://sites.google.com/site/xinxinzuohome/home>Xinxin Zuo</a>, <a href=https://www.ece.ualberta.ca/~lcheng5/>Li Cheng</a>, <a href=https://www.ece.ualberta.ca/~hai1/>Hai Jiang</a>, Juwei Lu"
venue: "ICLR"
# venue: "Arxiv Preprint"
# venue: "in: Submitted to CVPR"
arxiv: "https://openreview.net/pdf?id=d23EVDRJ6g"
# code: "https://github.com/JimmyZou/HumanPoseTracking_SNN"
website: "https://motiondreamer.github.io"
---
Localized masked modeling paradigm to learn motion
internal patterns from one motion with arbitrary topology.